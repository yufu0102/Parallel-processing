{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded successfully...\n",
      "\n",
      "讀取完畢 檔案分割成功\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-1-a398191f613c>:71: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda2\\envs\\parallel\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "開始訓練\n",
      "\n",
      "Epoch: 000/350 cost: 12.582519531\n",
      "Training accuracy: 0.300\n",
      "Epoch: 001/350 cost: 10.318268776\n",
      "Training accuracy: 0.530\n",
      "Epoch: 002/350 cost: 10.282422066\n",
      "Training accuracy: 0.540\n",
      "Epoch: 003/350 cost: 7.890991688\n",
      "Training accuracy: 0.600\n",
      "Epoch: 004/350 cost: 4.626994133\n",
      "Training accuracy: 0.720\n",
      "Epoch: 005/350 cost: 6.384871960\n",
      "Training accuracy: 0.600\n",
      "Epoch: 006/350 cost: 7.354812622\n",
      "Training accuracy: 0.570\n",
      "Epoch: 007/350 cost: 4.385900974\n",
      "Training accuracy: 0.770\n",
      "Epoch: 008/350 cost: 7.666756153\n",
      "Training accuracy: 0.600\n",
      "Epoch: 009/350 cost: 3.206178904\n",
      "Training accuracy: 0.710\n",
      "Epoch: 010/350 cost: 4.964400768\n",
      "Training accuracy: 0.650\n",
      "Epoch: 011/350 cost: 3.254843950\n",
      "Training accuracy: 0.640\n",
      "Epoch: 012/350 cost: 2.405421257\n",
      "Training accuracy: 0.690\n",
      "Epoch: 013/350 cost: 2.332925081\n",
      "Training accuracy: 0.750\n",
      "Epoch: 014/350 cost: 1.984068155\n",
      "Training accuracy: 0.720\n",
      "Epoch: 015/350 cost: 2.621792316\n",
      "Training accuracy: 0.660\n",
      "Epoch: 016/350 cost: 1.549727440\n",
      "Training accuracy: 0.760\n",
      "Epoch: 017/350 cost: 1.342184901\n",
      "Training accuracy: 0.760\n",
      "Epoch: 018/350 cost: 0.762628376\n",
      "Training accuracy: 0.840\n",
      "Epoch: 019/350 cost: 0.779765308\n",
      "Training accuracy: 0.840\n",
      "Epoch: 020/350 cost: 1.558699846\n",
      "Training accuracy: 0.740\n",
      "Epoch: 021/350 cost: 0.935189605\n",
      "Training accuracy: 0.790\n",
      "Epoch: 022/350 cost: 1.176374793\n",
      "Training accuracy: 0.780\n",
      "Epoch: 023/350 cost: 0.855435967\n",
      "Training accuracy: 0.820\n",
      "Epoch: 024/350 cost: 0.568252146\n",
      "Training accuracy: 0.820\n",
      "Epoch: 025/350 cost: 0.981848896\n",
      "Training accuracy: 0.770\n",
      "Epoch: 026/350 cost: 0.941726983\n",
      "Training accuracy: 0.820\n",
      "Epoch: 027/350 cost: 0.408574402\n",
      "Training accuracy: 0.880\n",
      "Epoch: 028/350 cost: 0.743111491\n",
      "Training accuracy: 0.870\n",
      "Epoch: 029/350 cost: 0.692589104\n",
      "Training accuracy: 0.810\n",
      "Epoch: 030/350 cost: 1.116236448\n",
      "Training accuracy: 0.840\n",
      "Epoch: 031/350 cost: 1.349117994\n",
      "Training accuracy: 0.820\n",
      "Epoch: 032/350 cost: 0.979390740\n",
      "Training accuracy: 0.900\n",
      "Epoch: 033/350 cost: 0.259824455\n",
      "Training accuracy: 0.930\n",
      "Epoch: 034/350 cost: 0.347793072\n",
      "Training accuracy: 0.850\n",
      "Epoch: 035/350 cost: 0.350472867\n",
      "Training accuracy: 0.880\n",
      "Epoch: 036/350 cost: 0.374136478\n",
      "Training accuracy: 0.880\n",
      "Epoch: 037/350 cost: 0.689932764\n",
      "Training accuracy: 0.900\n",
      "Epoch: 038/350 cost: 0.367325217\n",
      "Training accuracy: 0.850\n",
      "Epoch: 039/350 cost: 0.404753089\n",
      "Training accuracy: 0.920\n",
      "Epoch: 040/350 cost: 0.611050546\n",
      "Training accuracy: 0.880\n",
      "Epoch: 041/350 cost: 0.344959766\n",
      "Training accuracy: 0.950\n",
      "Epoch: 042/350 cost: 0.259573877\n",
      "Training accuracy: 0.960\n",
      "Epoch: 043/350 cost: 0.610554457\n",
      "Training accuracy: 0.900\n",
      "Epoch: 044/350 cost: 0.180720419\n",
      "Training accuracy: 0.920\n",
      "Epoch: 045/350 cost: 0.267009646\n",
      "Training accuracy: 0.930\n",
      "Epoch: 046/350 cost: 0.175244108\n",
      "Training accuracy: 0.960\n",
      "Epoch: 047/350 cost: 0.283461750\n",
      "Training accuracy: 0.960\n",
      "Epoch: 048/350 cost: 0.258776426\n",
      "Training accuracy: 0.950\n",
      "Epoch: 049/350 cost: 0.190264687\n",
      "Training accuracy: 0.940\n",
      "Epoch: 050/350 cost: 0.224015519\n",
      "Training accuracy: 0.930\n",
      "Epoch: 051/350 cost: 0.222390920\n",
      "Training accuracy: 0.900\n",
      "Epoch: 052/350 cost: 0.175562188\n",
      "Training accuracy: 0.950\n",
      "Epoch: 053/350 cost: 0.077034064\n",
      "Training accuracy: 0.990\n",
      "Epoch: 054/350 cost: 0.157555148\n",
      "Training accuracy: 0.960\n",
      "Epoch: 055/350 cost: 0.099829957\n",
      "Training accuracy: 0.950\n",
      "Epoch: 056/350 cost: 0.117940694\n",
      "Training accuracy: 0.970\n",
      "Epoch: 057/350 cost: 0.184807956\n",
      "Training accuracy: 0.920\n",
      "Epoch: 058/350 cost: 0.142117068\n",
      "Training accuracy: 0.950\n",
      "Epoch: 059/350 cost: 0.085935026\n",
      "Training accuracy: 0.960\n",
      "Epoch: 060/350 cost: 0.197175011\n",
      "Training accuracy: 0.930\n",
      "Epoch: 061/350 cost: 0.070103295\n",
      "Training accuracy: 0.970\n",
      "Epoch: 062/350 cost: 0.069268391\n",
      "Training accuracy: 0.970\n",
      "Epoch: 063/350 cost: 0.087671652\n",
      "Training accuracy: 0.970\n",
      "Epoch: 064/350 cost: 0.052765980\n",
      "Training accuracy: 0.980\n",
      "Epoch: 065/350 cost: 0.061781865\n",
      "Training accuracy: 0.990\n",
      "Epoch: 066/350 cost: 0.073562987\n",
      "Training accuracy: 0.970\n",
      "Epoch: 067/350 cost: 0.069415301\n",
      "Training accuracy: 0.960\n",
      "Epoch: 068/350 cost: 0.023393793\n",
      "Training accuracy: 1.000\n",
      "Epoch: 069/350 cost: 0.059953243\n",
      "Training accuracy: 0.990\n",
      "Epoch: 070/350 cost: 0.025733612\n",
      "Training accuracy: 0.990\n",
      "Epoch: 071/350 cost: 0.064741313\n",
      "Training accuracy: 0.970\n",
      "Epoch: 072/350 cost: 0.068635166\n",
      "Training accuracy: 0.960\n",
      "Epoch: 073/350 cost: 0.040741239\n",
      "Training accuracy: 0.990\n",
      "Epoch: 074/350 cost: 0.041486021\n",
      "Training accuracy: 0.980\n",
      "Epoch: 075/350 cost: 0.032891076\n",
      "Training accuracy: 0.990\n",
      "Epoch: 076/350 cost: 0.038851112\n",
      "Training accuracy: 1.000\n",
      "Epoch: 077/350 cost: 0.141959026\n",
      "Training accuracy: 0.980\n",
      "Epoch: 078/350 cost: 0.070244201\n",
      "Training accuracy: 0.990\n",
      "Epoch: 079/350 cost: 0.030953750\n",
      "Training accuracy: 0.980\n",
      "Epoch: 080/350 cost: 0.100328691\n",
      "Training accuracy: 0.980\n",
      "Epoch: 081/350 cost: 0.051351923\n",
      "Training accuracy: 1.000\n",
      "Epoch: 082/350 cost: 0.057505827\n",
      "Training accuracy: 0.980\n",
      "Epoch: 083/350 cost: 0.034717236\n",
      "Training accuracy: 1.000\n",
      "Epoch: 084/350 cost: 0.046092521\n",
      "Training accuracy: 0.990\n",
      "Epoch: 085/350 cost: 0.033021890\n",
      "Training accuracy: 1.000\n",
      "Epoch: 086/350 cost: 0.087140039\n",
      "Training accuracy: 0.980\n",
      "Epoch: 087/350 cost: 0.022202156\n",
      "Training accuracy: 1.000\n",
      "Epoch: 088/350 cost: 0.063968621\n",
      "Training accuracy: 0.980\n",
      "Epoch: 089/350 cost: 0.061258815\n",
      "Training accuracy: 0.980\n",
      "Epoch: 090/350 cost: 0.057788759\n",
      "Training accuracy: 0.990\n",
      "Epoch: 091/350 cost: 0.063365676\n",
      "Training accuracy: 0.990\n",
      "Epoch: 092/350 cost: 0.023055417\n",
      "Training accuracy: 1.000\n",
      "Epoch: 093/350 cost: 0.040840935\n",
      "Training accuracy: 0.990\n",
      "Epoch: 094/350 cost: 0.036525454\n",
      "Training accuracy: 0.990\n",
      "Epoch: 095/350 cost: 0.089925505\n",
      "Training accuracy: 0.960\n",
      "Epoch: 096/350 cost: 0.023044705\n",
      "Training accuracy: 0.990\n",
      "Epoch: 097/350 cost: 0.136110321\n",
      "Training accuracy: 0.940\n",
      "Epoch: 098/350 cost: 0.108798802\n",
      "Training accuracy: 0.960\n",
      "Epoch: 099/350 cost: 0.081689127\n",
      "Training accuracy: 0.950\n",
      "Epoch: 100/350 cost: 0.260061145\n",
      "Training accuracy: 0.950\n",
      "Epoch: 101/350 cost: 0.139515802\n",
      "Training accuracy: 0.920\n",
      "Epoch: 102/350 cost: 0.563783765\n",
      "Training accuracy: 0.860\n",
      "Epoch: 103/350 cost: 0.264608562\n",
      "Training accuracy: 0.920\n",
      "Epoch: 104/350 cost: 0.128134817\n",
      "Training accuracy: 0.960\n",
      "Epoch: 105/350 cost: 0.226769984\n",
      "Training accuracy: 0.930\n",
      "Epoch: 106/350 cost: 0.133934572\n",
      "Training accuracy: 0.960\n",
      "Epoch: 107/350 cost: 0.148164392\n",
      "Training accuracy: 0.960\n",
      "Epoch: 108/350 cost: 0.247340396\n",
      "Training accuracy: 0.900\n",
      "Epoch: 109/350 cost: 0.178312153\n",
      "Training accuracy: 0.940\n",
      "Epoch: 110/350 cost: 0.114327028\n",
      "Training accuracy: 0.960\n",
      "Epoch: 111/350 cost: 0.195158899\n",
      "Training accuracy: 0.930\n",
      "Epoch: 112/350 cost: 0.130679622\n",
      "Training accuracy: 0.940\n",
      "Epoch: 113/350 cost: 0.135107279\n",
      "Training accuracy: 0.950\n",
      "Epoch: 114/350 cost: 0.079218954\n",
      "Training accuracy: 0.970\n",
      "Epoch: 115/350 cost: 0.158416450\n",
      "Training accuracy: 0.970\n",
      "Epoch: 116/350 cost: 0.088146381\n",
      "Training accuracy: 0.980\n",
      "Epoch: 117/350 cost: 0.145336911\n",
      "Training accuracy: 0.960\n",
      "Epoch: 118/350 cost: 0.299725503\n",
      "Training accuracy: 0.930\n",
      "Epoch: 119/350 cost: 0.246629715\n",
      "Training accuracy: 0.920\n",
      "Epoch: 120/350 cost: 0.302784860\n",
      "Training accuracy: 0.880\n",
      "Epoch: 121/350 cost: 0.126046434\n",
      "Training accuracy: 0.970\n",
      "Epoch: 122/350 cost: 0.095223486\n",
      "Training accuracy: 0.980\n",
      "Epoch: 123/350 cost: 0.115350343\n",
      "Training accuracy: 0.960\n",
      "Epoch: 124/350 cost: 0.262109429\n",
      "Training accuracy: 0.900\n",
      "Epoch: 125/350 cost: 0.319645554\n",
      "Training accuracy: 0.900\n",
      "Epoch: 126/350 cost: 0.410904974\n",
      "Training accuracy: 0.930\n",
      "Epoch: 127/350 cost: 0.197057843\n",
      "Training accuracy: 0.930\n",
      "Epoch: 128/350 cost: 0.341462135\n",
      "Training accuracy: 0.880\n",
      "Epoch: 129/350 cost: 0.237024769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.960\n",
      "Epoch: 130/350 cost: 0.240266249\n",
      "Training accuracy: 0.910\n",
      "Epoch: 131/350 cost: 0.178478867\n",
      "Training accuracy: 0.910\n",
      "Epoch: 132/350 cost: 0.218792155\n",
      "Training accuracy: 0.900\n",
      "Epoch: 133/350 cost: 0.207554117\n",
      "Training accuracy: 0.930\n",
      "Epoch: 134/350 cost: 0.158463970\n",
      "Training accuracy: 0.950\n",
      "Epoch: 135/350 cost: 0.135016799\n",
      "Training accuracy: 0.920\n",
      "Epoch: 136/350 cost: 0.302147031\n",
      "Training accuracy: 0.910\n",
      "Epoch: 137/350 cost: 0.189288870\n",
      "Training accuracy: 0.970\n",
      "Epoch: 138/350 cost: 0.184369549\n",
      "Training accuracy: 0.920\n",
      "Epoch: 139/350 cost: 0.149155259\n",
      "Training accuracy: 0.950\n",
      "Epoch: 140/350 cost: 0.178555757\n",
      "Training accuracy: 0.940\n",
      "Epoch: 141/350 cost: 0.183086678\n",
      "Training accuracy: 0.910\n",
      "Epoch: 142/350 cost: 0.386295080\n",
      "Training accuracy: 0.900\n",
      "Epoch: 143/350 cost: 0.165251791\n",
      "Training accuracy: 0.950\n",
      "Epoch: 144/350 cost: 0.125727355\n",
      "Training accuracy: 0.950\n",
      "Epoch: 145/350 cost: 0.156072468\n",
      "Training accuracy: 0.950\n",
      "Epoch: 146/350 cost: 0.106329463\n",
      "Training accuracy: 0.970\n",
      "Epoch: 147/350 cost: 0.094233267\n",
      "Training accuracy: 0.970\n",
      "Epoch: 148/350 cost: 0.142419338\n",
      "Training accuracy: 0.940\n",
      "Epoch: 149/350 cost: 0.141358942\n",
      "Training accuracy: 0.930\n",
      "Epoch: 150/350 cost: 0.110974275\n",
      "Training accuracy: 0.960\n",
      "Epoch: 151/350 cost: 0.085350059\n",
      "Training accuracy: 0.960\n",
      "Epoch: 152/350 cost: 0.064272083\n",
      "Training accuracy: 0.980\n",
      "Epoch: 153/350 cost: 0.191656411\n",
      "Training accuracy: 0.930\n",
      "Epoch: 154/350 cost: 0.150606483\n",
      "Training accuracy: 0.940\n",
      "Epoch: 155/350 cost: 0.139699176\n",
      "Training accuracy: 0.970\n",
      "Epoch: 156/350 cost: 0.265204400\n",
      "Training accuracy: 0.900\n",
      "Epoch: 157/350 cost: 0.162376523\n",
      "Training accuracy: 0.960\n",
      "Epoch: 158/350 cost: 0.223479658\n",
      "Training accuracy: 0.940\n",
      "Epoch: 159/350 cost: 0.145150870\n",
      "Training accuracy: 0.960\n",
      "Epoch: 160/350 cost: 0.164106011\n",
      "Training accuracy: 0.950\n",
      "Epoch: 161/350 cost: 0.099751122\n",
      "Training accuracy: 0.970\n",
      "Epoch: 162/350 cost: 0.109572791\n",
      "Training accuracy: 0.940\n",
      "Epoch: 163/350 cost: 0.036022726\n",
      "Training accuracy: 0.990\n",
      "Epoch: 164/350 cost: 0.170770496\n",
      "Training accuracy: 0.920\n",
      "Epoch: 165/350 cost: 0.122293495\n",
      "Training accuracy: 0.950\n",
      "Epoch: 166/350 cost: 0.054797031\n",
      "Training accuracy: 0.970\n",
      "Epoch: 167/350 cost: 0.285104454\n",
      "Training accuracy: 0.930\n",
      "Epoch: 168/350 cost: 0.402088851\n",
      "Training accuracy: 0.900\n",
      "Epoch: 169/350 cost: 0.377405405\n",
      "Training accuracy: 0.830\n",
      "Epoch: 170/350 cost: 0.451886892\n",
      "Training accuracy: 0.880\n",
      "Epoch: 171/350 cost: 0.156569555\n",
      "Training accuracy: 0.930\n",
      "Epoch: 172/350 cost: 0.321364582\n",
      "Training accuracy: 0.920\n",
      "Epoch: 173/350 cost: 0.162468493\n",
      "Training accuracy: 0.970\n",
      "Epoch: 174/350 cost: 0.172553271\n",
      "Training accuracy: 0.930\n",
      "Epoch: 175/350 cost: 0.171862170\n",
      "Training accuracy: 0.930\n",
      "Epoch: 176/350 cost: 0.308620304\n",
      "Training accuracy: 0.890\n",
      "Epoch: 177/350 cost: 0.465651214\n",
      "Training accuracy: 0.890\n",
      "Epoch: 178/350 cost: 0.657523930\n",
      "Training accuracy: 0.800\n",
      "Epoch: 179/350 cost: 0.222606465\n",
      "Training accuracy: 0.950\n",
      "Epoch: 180/350 cost: 0.543187499\n",
      "Training accuracy: 0.930\n",
      "Epoch: 181/350 cost: 0.261590362\n",
      "Training accuracy: 0.940\n",
      "Epoch: 182/350 cost: 0.245602608\n",
      "Training accuracy: 0.940\n",
      "Epoch: 183/350 cost: 0.474091768\n",
      "Training accuracy: 0.910\n",
      "Epoch: 184/350 cost: 0.255247772\n",
      "Training accuracy: 0.920\n",
      "Epoch: 185/350 cost: 0.287425071\n",
      "Training accuracy: 0.920\n",
      "Epoch: 186/350 cost: 0.348117918\n",
      "Training accuracy: 0.910\n",
      "Epoch: 187/350 cost: 0.190527558\n",
      "Training accuracy: 0.910\n",
      "Epoch: 188/350 cost: 0.206792176\n",
      "Training accuracy: 0.940\n",
      "Epoch: 189/350 cost: 0.505765021\n",
      "Training accuracy: 0.870\n",
      "Epoch: 190/350 cost: 0.391612738\n",
      "Training accuracy: 0.920\n",
      "Epoch: 191/350 cost: 0.311793834\n",
      "Training accuracy: 0.910\n",
      "Epoch: 192/350 cost: 0.306043118\n",
      "Training accuracy: 0.890\n",
      "Epoch: 193/350 cost: 0.415103644\n",
      "Training accuracy: 0.890\n",
      "Epoch: 194/350 cost: 0.219594821\n",
      "Training accuracy: 0.910\n",
      "Epoch: 195/350 cost: 0.338047445\n",
      "Training accuracy: 0.910\n",
      "Epoch: 196/350 cost: 0.166791767\n",
      "Training accuracy: 0.970\n",
      "Epoch: 197/350 cost: 0.274966270\n",
      "Training accuracy: 0.900\n",
      "Epoch: 198/350 cost: 0.165156379\n",
      "Training accuracy: 0.960\n",
      "Epoch: 199/350 cost: 0.100128949\n",
      "Training accuracy: 0.960\n",
      "Epoch: 200/350 cost: 0.222532958\n",
      "Training accuracy: 0.910\n",
      "Epoch: 201/350 cost: 0.213791296\n",
      "Training accuracy: 0.940\n",
      "Epoch: 202/350 cost: 0.243637651\n",
      "Training accuracy: 0.900\n",
      "Epoch: 203/350 cost: 0.220629692\n",
      "Training accuracy: 0.950\n",
      "Epoch: 204/350 cost: 0.164476275\n",
      "Training accuracy: 0.920\n",
      "Epoch: 205/350 cost: 0.263120949\n",
      "Training accuracy: 0.900\n",
      "Epoch: 206/350 cost: 0.265673041\n",
      "Training accuracy: 0.930\n",
      "Epoch: 207/350 cost: 0.249392182\n",
      "Training accuracy: 0.880\n",
      "Epoch: 208/350 cost: 0.245826811\n",
      "Training accuracy: 0.920\n",
      "Epoch: 209/350 cost: 0.312256426\n",
      "Training accuracy: 0.920\n",
      "Epoch: 210/350 cost: 0.241072029\n",
      "Training accuracy: 0.890\n",
      "Epoch: 211/350 cost: 0.359600872\n",
      "Training accuracy: 0.890\n",
      "Epoch: 212/350 cost: 0.186135858\n",
      "Training accuracy: 0.920\n",
      "Epoch: 213/350 cost: 0.298189342\n",
      "Training accuracy: 0.930\n",
      "Epoch: 214/350 cost: 0.100979708\n",
      "Training accuracy: 0.960\n",
      "Epoch: 215/350 cost: 0.136966929\n",
      "Training accuracy: 0.950\n",
      "Epoch: 216/350 cost: 0.329098344\n",
      "Training accuracy: 0.910\n",
      "Epoch: 217/350 cost: 0.198091999\n",
      "Training accuracy: 0.920\n",
      "Epoch: 218/350 cost: 0.143500552\n",
      "Training accuracy: 0.940\n",
      "Epoch: 219/350 cost: 0.265430242\n",
      "Training accuracy: 0.900\n",
      "Epoch: 220/350 cost: 0.122388288\n",
      "Training accuracy: 0.950\n",
      "Epoch: 221/350 cost: 0.155728281\n",
      "Training accuracy: 0.950\n",
      "Epoch: 222/350 cost: 0.170927390\n",
      "Training accuracy: 0.930\n",
      "Epoch: 223/350 cost: 0.142475128\n",
      "Training accuracy: 0.930\n",
      "Epoch: 224/350 cost: 0.144607946\n",
      "Training accuracy: 0.950\n",
      "Epoch: 225/350 cost: 0.233295575\n",
      "Training accuracy: 0.960\n",
      "Epoch: 226/350 cost: 0.149021029\n",
      "Training accuracy: 0.960\n",
      "Epoch: 227/350 cost: 0.407135457\n",
      "Training accuracy: 0.900\n",
      "Epoch: 228/350 cost: 0.354341805\n",
      "Training accuracy: 0.890\n",
      "Epoch: 229/350 cost: 0.113468133\n",
      "Training accuracy: 0.950\n",
      "Epoch: 230/350 cost: 0.109805867\n",
      "Training accuracy: 0.960\n",
      "Epoch: 231/350 cost: 0.331913769\n",
      "Training accuracy: 0.880\n",
      "Epoch: 232/350 cost: 0.177541107\n",
      "Training accuracy: 0.930\n",
      "Epoch: 233/350 cost: 0.230779245\n",
      "Training accuracy: 0.900\n",
      "Epoch: 234/350 cost: 0.130345061\n",
      "Training accuracy: 0.950\n",
      "Epoch: 235/350 cost: 0.464543253\n",
      "Training accuracy: 0.790\n",
      "Epoch: 236/350 cost: 0.431733161\n",
      "Training accuracy: 0.910\n",
      "Epoch: 237/350 cost: 0.375027418\n",
      "Training accuracy: 0.910\n",
      "Epoch: 238/350 cost: 0.203482568\n",
      "Training accuracy: 0.940\n",
      "Epoch: 239/350 cost: 0.379234612\n",
      "Training accuracy: 0.890\n",
      "Epoch: 240/350 cost: 0.476411402\n",
      "Training accuracy: 0.900\n",
      "Epoch: 241/350 cost: 0.512752354\n",
      "Training accuracy: 0.820\n",
      "Epoch: 242/350 cost: 0.423851460\n",
      "Training accuracy: 0.890\n",
      "Epoch: 243/350 cost: 0.636021554\n",
      "Training accuracy: 0.790\n",
      "Epoch: 244/350 cost: 0.354282379\n",
      "Training accuracy: 0.870\n",
      "Epoch: 245/350 cost: 0.308494747\n",
      "Training accuracy: 0.930\n",
      "Epoch: 246/350 cost: 0.421693802\n",
      "Training accuracy: 0.850\n",
      "Epoch: 247/350 cost: 0.330838233\n",
      "Training accuracy: 0.880\n",
      "Epoch: 248/350 cost: 0.414386362\n",
      "Training accuracy: 0.890\n",
      "Epoch: 249/350 cost: 0.307278275\n",
      "Training accuracy: 0.870\n",
      "Epoch: 250/350 cost: 0.319011807\n",
      "Training accuracy: 0.890\n",
      "Epoch: 251/350 cost: 0.369018137\n",
      "Training accuracy: 0.840\n",
      "Epoch: 252/350 cost: 0.425718307\n",
      "Training accuracy: 0.900\n",
      "Epoch: 253/350 cost: 0.344128519\n",
      "Training accuracy: 0.900\n",
      "Epoch: 254/350 cost: 0.264308214\n",
      "Training accuracy: 0.900\n",
      "Epoch: 255/350 cost: 0.581969798\n",
      "Training accuracy: 0.830\n",
      "Epoch: 256/350 cost: 0.375284612\n",
      "Training accuracy: 0.870\n",
      "Epoch: 257/350 cost: 0.295705616\n",
      "Training accuracy: 0.850\n",
      "Epoch: 258/350 cost: 0.215934768\n",
      "Training accuracy: 0.900\n",
      "Epoch: 259/350 cost: 0.224432528\n",
      "Training accuracy: 0.910\n",
      "Epoch: 260/350 cost: 0.170064360\n",
      "Training accuracy: 0.920\n",
      "Epoch: 261/350 cost: 0.362798601\n",
      "Training accuracy: 0.890\n",
      "Epoch: 262/350 cost: 0.210950911\n",
      "Training accuracy: 0.930\n",
      "Epoch: 263/350 cost: 0.196557224\n",
      "Training accuracy: 0.900\n",
      "Epoch: 264/350 cost: 0.207345948\n",
      "Training accuracy: 0.910\n",
      "Epoch: 265/350 cost: 0.461389273\n",
      "Training accuracy: 0.860\n",
      "Epoch: 266/350 cost: 0.244790077\n",
      "Training accuracy: 0.930\n",
      "Epoch: 267/350 cost: 0.138887256\n",
      "Training accuracy: 0.930\n",
      "Epoch: 268/350 cost: 0.351299018\n",
      "Training accuracy: 0.890\n",
      "Epoch: 269/350 cost: 0.367430776\n",
      "Training accuracy: 0.910\n",
      "Epoch: 270/350 cost: 0.403682858\n",
      "Training accuracy: 0.890\n",
      "Epoch: 271/350 cost: 0.317216098\n",
      "Training accuracy: 0.900\n",
      "Epoch: 272/350 cost: 0.361164689\n",
      "Training accuracy: 0.940\n",
      "Epoch: 273/350 cost: 0.458243728\n",
      "Training accuracy: 0.860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 274/350 cost: 0.283169627\n",
      "Training accuracy: 0.900\n",
      "Epoch: 275/350 cost: 0.240085989\n",
      "Training accuracy: 0.940\n",
      "Epoch: 276/350 cost: 0.660145521\n",
      "Training accuracy: 0.860\n",
      "Epoch: 277/350 cost: 0.374904662\n",
      "Training accuracy: 0.900\n",
      "Epoch: 278/350 cost: 0.636112690\n",
      "Training accuracy: 0.790\n",
      "Epoch: 279/350 cost: 0.612725317\n",
      "Training accuracy: 0.730\n",
      "Epoch: 280/350 cost: 0.494627506\n",
      "Training accuracy: 0.810\n",
      "Epoch: 281/350 cost: 0.485589832\n",
      "Training accuracy: 0.850\n",
      "Epoch: 282/350 cost: 0.705573738\n",
      "Training accuracy: 0.770\n",
      "Epoch: 283/350 cost: 0.438620448\n",
      "Training accuracy: 0.860\n",
      "Epoch: 284/350 cost: 0.429703295\n",
      "Training accuracy: 0.860\n",
      "Epoch: 285/350 cost: 0.507867992\n",
      "Training accuracy: 0.830\n",
      "Epoch: 286/350 cost: 0.367292494\n",
      "Training accuracy: 0.890\n",
      "Epoch: 287/350 cost: 0.399346322\n",
      "Training accuracy: 0.900\n",
      "Epoch: 288/350 cost: 0.495057464\n",
      "Training accuracy: 0.850\n",
      "Epoch: 289/350 cost: 0.101174161\n",
      "Training accuracy: 0.980\n",
      "Epoch: 290/350 cost: 0.353420287\n",
      "Training accuracy: 0.880\n",
      "Epoch: 291/350 cost: 0.285084218\n",
      "Training accuracy: 0.900\n",
      "Epoch: 292/350 cost: 0.277790248\n",
      "Training accuracy: 0.890\n",
      "Epoch: 293/350 cost: 0.295614094\n",
      "Training accuracy: 0.900\n",
      "Epoch: 294/350 cost: 0.292377353\n",
      "Training accuracy: 0.880\n",
      "Epoch: 295/350 cost: 0.373063207\n",
      "Training accuracy: 0.900\n",
      "Epoch: 296/350 cost: 0.331834286\n",
      "Training accuracy: 0.890\n",
      "Epoch: 297/350 cost: 0.416442752\n",
      "Training accuracy: 0.860\n",
      "Epoch: 298/350 cost: 0.261370718\n",
      "Training accuracy: 0.910\n",
      "Epoch: 299/350 cost: 0.247503057\n",
      "Training accuracy: 0.920\n",
      "Epoch: 300/350 cost: 0.188460350\n",
      "Training accuracy: 0.950\n",
      "Epoch: 301/350 cost: 0.413906693\n",
      "Training accuracy: 0.840\n",
      "Epoch: 302/350 cost: 0.320378453\n",
      "Training accuracy: 0.900\n",
      "Epoch: 303/350 cost: 0.268161327\n",
      "Training accuracy: 0.860\n",
      "Epoch: 304/350 cost: 0.161459982\n",
      "Training accuracy: 0.940\n",
      "Epoch: 305/350 cost: 0.269176036\n",
      "Training accuracy: 0.920\n",
      "Epoch: 306/350 cost: 0.233255267\n",
      "Training accuracy: 0.950\n",
      "Epoch: 307/350 cost: 0.118312031\n",
      "Training accuracy: 0.940\n",
      "Epoch: 308/350 cost: 0.203389034\n",
      "Training accuracy: 0.950\n",
      "Epoch: 309/350 cost: 0.136728689\n",
      "Training accuracy: 0.940\n",
      "Epoch: 310/350 cost: 0.296415538\n",
      "Training accuracy: 0.920\n",
      "Epoch: 311/350 cost: 0.139748022\n",
      "Training accuracy: 0.960\n",
      "Epoch: 312/350 cost: 0.137555405\n",
      "Training accuracy: 0.940\n",
      "Epoch: 313/350 cost: 0.297326297\n",
      "Training accuracy: 0.900\n",
      "Epoch: 314/350 cost: 0.241870269\n",
      "Training accuracy: 0.930\n",
      "Epoch: 315/350 cost: 0.206841648\n",
      "Training accuracy: 0.930\n",
      "Epoch: 316/350 cost: 0.136906758\n",
      "Training accuracy: 0.960\n",
      "Epoch: 317/350 cost: 0.183616430\n",
      "Training accuracy: 0.950\n",
      "Epoch: 318/350 cost: 0.174680009\n",
      "Training accuracy: 0.950\n",
      "Epoch: 319/350 cost: 0.284208298\n",
      "Training accuracy: 0.880\n",
      "Epoch: 320/350 cost: 0.206920877\n",
      "Training accuracy: 0.910\n",
      "Epoch: 321/350 cost: 0.254810154\n",
      "Training accuracy: 0.910\n",
      "Epoch: 322/350 cost: 0.201680094\n",
      "Training accuracy: 0.940\n",
      "Epoch: 323/350 cost: 0.195230961\n",
      "Training accuracy: 0.950\n",
      "Epoch: 324/350 cost: 0.126915336\n",
      "Training accuracy: 0.950\n",
      "Epoch: 325/350 cost: 0.131930903\n",
      "Training accuracy: 0.940\n",
      "Epoch: 326/350 cost: 0.142659977\n",
      "Training accuracy: 0.960\n",
      "Epoch: 327/350 cost: 0.278209835\n",
      "Training accuracy: 0.890\n",
      "Epoch: 328/350 cost: 0.187003732\n",
      "Training accuracy: 0.940\n",
      "Epoch: 329/350 cost: 0.121371105\n",
      "Training accuracy: 0.970\n",
      "Epoch: 330/350 cost: 0.169457868\n",
      "Training accuracy: 0.930\n",
      "Epoch: 331/350 cost: 0.164995611\n",
      "Training accuracy: 0.920\n",
      "Epoch: 332/350 cost: 0.217893273\n",
      "Training accuracy: 0.890\n",
      "Epoch: 333/350 cost: 0.122581117\n",
      "Training accuracy: 0.940\n",
      "Epoch: 334/350 cost: 0.093308069\n",
      "Training accuracy: 0.980\n",
      "Epoch: 335/350 cost: 0.091309331\n",
      "Training accuracy: 0.970\n",
      "Epoch: 336/350 cost: 0.114285201\n",
      "Training accuracy: 0.950\n",
      "Epoch: 337/350 cost: 0.139671028\n",
      "Training accuracy: 0.970\n",
      "Epoch: 338/350 cost: 0.169901997\n",
      "Training accuracy: 0.940\n",
      "Epoch: 339/350 cost: 0.082436122\n",
      "Training accuracy: 0.970\n",
      "Epoch: 340/350 cost: 0.075464018\n",
      "Training accuracy: 0.970\n",
      "Epoch: 341/350 cost: 0.156351551\n",
      "Training accuracy: 0.970\n",
      "Epoch: 342/350 cost: 0.132668823\n",
      "Training accuracy: 0.930\n",
      "Epoch: 343/350 cost: 0.124049097\n",
      "Training accuracy: 0.940\n",
      "Epoch: 344/350 cost: 0.134851173\n",
      "Training accuracy: 0.930\n",
      "Epoch: 345/350 cost: 0.159874514\n",
      "Training accuracy: 0.920\n",
      "Epoch: 346/350 cost: 0.125156760\n",
      "Training accuracy: 0.940\n",
      "Epoch: 347/350 cost: 0.152187809\n",
      "Training accuracy: 0.950\n",
      "Epoch: 348/350 cost: 0.058961954\n",
      "Training accuracy: 1.000\n",
      "Epoch: 349/350 cost: 0.123468854\n",
      "Training accuracy: 0.960\n",
      "訓練完成\n",
      "開始測試...\n",
      "\n",
      "Test accuracy: 0.591\n",
      "Session closed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1da209097f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1da209488d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FILE_PATH = 'glass.csv'                                # csv path\n",
    "raw_data = pd.read_csv(FILE_PATH)\t\t\t\t\t\t    \n",
    "\n",
    "print(\"Raw data loaded successfully...\\n\")\n",
    "#------------------------------------------------------------------------------\n",
    "# 參數\n",
    "\n",
    "Y_LABEL = 'Type'                                   \t\t    \t# 結果label\n",
    "KEYS = [i for i in raw_data.keys().tolist() if i != Y_LABEL]\t# 用來運算預測的key\n",
    "N_INSTANCES = raw_data.shape[0]                     \t\t\t# Number of instances\n",
    "N_INPUT = raw_data.shape[1] - 1                     \t\t\t# Input size\n",
    "N_CLASSES = 8                                                   # 類型數\n",
    "TEST_SIZE = 0.1                                    \t\t\t    # 測試數\n",
    "TRAIN_SIZE = int(N_INSTANCES * (1 - TEST_SIZE))     \t\t\t# 訓練大小\n",
    "LEARNING_RATE = 0.001                              \t\t\t    # 學習rate\n",
    "TRAINING_EPOCHS = 350                               \t\t\t# epochs\n",
    "BATCH_SIZE = 100                                    \t\t\t# Batch size\n",
    "DISPLAY_STEP = 1                                    \t\t\t# Display progress each x epochs\n",
    "HIDDEN_SIZE = 1000\t                                   \t    \t# Number of hidden neurons\n",
    "STDDEV = 0.1                                        \t\t\t# Standard deviation (for weights random init)\n",
    "RANDOM_STATE = 100 \t\t\t\t\t\t\t\t\t            # Random state for train_test_split\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Loading data\n",
    "\n",
    "# Load data\n",
    "data = raw_data[KEYS].get_values()                  \t\t\t# X data\n",
    "labels = raw_data[Y_LABEL].get_values()             \t\t\t# y data\n",
    "# One hot encoding for labels\n",
    "labels_ = np.zeros((N_INSTANCES, N_CLASSES))\n",
    "labels_[np.arange(N_INSTANCES), labels] = 1\n",
    "\n",
    "# Train-test split\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data,\n",
    "                                                                    labels_,\n",
    "                                                                    test_size = TEST_SIZE,\n",
    "                                                                    random_state = RANDOM_STATE)\n",
    "\n",
    "print(\"讀取完畢 檔案分割成功\\n\")\n",
    "#------------------------------------------------------------------------------\n",
    "#神經網路架構\n",
    "\n",
    "# Tf placeholders\n",
    "X = tf.placeholder(tf.float32, [None, N_INPUT])\n",
    "y = tf.placeholder(tf.float32, [None, N_CLASSES])\n",
    "dropout_keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# 自定義層次函數\n",
    "def layer(output_dim, input_dim, inputs, activation = None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs\n",
    "\n",
    "# Build model\n",
    "h1 = layer(output_dim = HIDDEN_SIZE, input_dim = N_INPUT, inputs = X, activation = tf.nn.tanh)\n",
    "h2 = layer(output_dim = HIDDEN_SIZE, input_dim = HIDDEN_SIZE, inputs = h1, activation = tf.nn.tanh)\n",
    "h3 = layer(output_dim = HIDDEN_SIZE, input_dim = HIDDEN_SIZE, inputs = h2, activation = tf.nn.tanh)\n",
    "pred = layer(output_dim = N_CLASSES, input_dim = HIDDEN_SIZE, inputs = h3, activation = None)\n",
    "#loss以及優化公式\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE).minimize(cost)\n",
    "\n",
    "#計算正確率\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#初始化\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "print(\"開始訓練\\n\")\n",
    "#------------------------------------------------------------------------------\n",
    "# Training\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "loss_list = []\n",
    "epoch_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "#訓練迴圈\n",
    "for epoch in range(TRAINING_EPOCHS):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(data_train.shape[0] / BATCH_SIZE)\n",
    "    #batches\n",
    "    for i in range(total_batch):\n",
    "        randidx = np.random.randint(int(TRAIN_SIZE), size = BATCH_SIZE)\n",
    "        batch_xs = data_train[randidx, :]\n",
    "        batch_ys = labels_train[randidx, :]\n",
    "        #優化\n",
    "        sess.run(optimizer, feed_dict={X: batch_xs, y: batch_ys, dropout_keep_prob: 0.9})\n",
    "        #平均loss\n",
    "        avg_cost += sess.run(cost, feed_dict={X: batch_xs, y: batch_ys, dropout_keep_prob:1.})/total_batch\n",
    "    #log\n",
    "    if epoch % DISPLAY_STEP == 0:\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, TRAINING_EPOCHS, avg_cost))\n",
    "        train_acc = sess.run(accuracy, feed_dict={X: batch_xs, y: batch_ys, dropout_keep_prob:1.})\n",
    "        print (\"Training accuracy: %.3f\" % (train_acc))\n",
    "        epoch_list.append(epoch)\n",
    "        loss_list.append(avg_cost)\n",
    "        accuracy_list.append(train_acc)\n",
    "\n",
    "\n",
    "\n",
    "print (\"訓練完成\")\n",
    "print(\"開始測試...\\n\")\n",
    "#------------------------------------------------------------------------------\n",
    "# Testing\n",
    "\n",
    "test_acc = sess.run(accuracy, feed_dict={X: data_test, y: labels_test, dropout_keep_prob:1.})\n",
    "print (\"Test accuracy: %.3f\" % (test_acc))\n",
    "\n",
    "sess.close()\n",
    "print(\"Session closed!\")\n",
    "\n",
    "#顯示曲線圖\n",
    "#%matplotlib inline\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(5, 3)\n",
    "plt.plot(epoch_list, loss_list, label = 'loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss'], loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(5, 3)\n",
    "plt.plot(epoch_list, accuracy_list, label = 'accuracy')\n",
    "\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

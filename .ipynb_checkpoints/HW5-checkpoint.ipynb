{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------介面初始化----------\n",
      "----------讀取並合併圖片----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\envs\\parallel\\lib\\site-packages\\ipykernel_launcher.py:41: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_1 (Dropout)          (None, 340, 255, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 338, 253, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 338, 253, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 169, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 167, 124, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 167, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 83, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 81, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 81, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 311040)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                19906624  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 19,935,589\n",
      "Trainable params: 19,935,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "3890/3890 [==============================] - 340s 87ms/step - loss: 13.5805 - acc: 0.2247\n",
      "Epoch 2/150\n",
      "3890/3890 [==============================] - 343s 88ms/step - loss: 12.9073 - acc: 0.2252\n",
      "Epoch 3/150\n",
      "3890/3890 [==============================] - 345s 89ms/step - loss: 13.2696 - acc: 0.1902\n",
      "Epoch 4/150\n",
      "3890/3890 [==============================] - 522s 134ms/step - loss: 13.5177 - acc: 0.1789\n",
      "Epoch 5/150\n",
      "3890/3890 [==============================] - 463s 119ms/step - loss: 13.2298 - acc: 0.1866\n",
      "Epoch 6/150\n",
      "3890/3890 [==============================] - 520s 134ms/step - loss: 12.7874 - acc: 0.2213\n",
      "Epoch 7/150\n",
      "3890/3890 [==============================] - 490s 126ms/step - loss: 12.3631 - acc: 0.2463\n",
      "Epoch 8/150\n",
      "3890/3890 [==============================] - 334s 86ms/step - loss: 12.9060 - acc: 0.2141\n",
      "Epoch 9/150\n",
      "3890/3890 [==============================] - 304s 78ms/step - loss: 12.8039 - acc: 0.2237\n",
      "Epoch 10/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 12.9505 - acc: 0.2203\n",
      "Epoch 11/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 12.7183 - acc: 0.2270\n",
      "Epoch 12/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 12.4277 - acc: 0.2422\n",
      "Epoch 13/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 12.3196 - acc: 0.2460\n",
      "Epoch 14/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 12.3366 - acc: 0.2460\n",
      "Epoch 15/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 12.3668 - acc: 0.2411\n",
      "Epoch 16/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 13.5775 - acc: 0.1792\n",
      "Epoch 17/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 13.4914 - acc: 0.1717\n",
      "Epoch 18/150\n",
      "3890/3890 [==============================] - 291s 75ms/step - loss: 13.4578 - acc: 0.1746\n",
      "Epoch 19/150\n",
      "3890/3890 [==============================] - 291s 75ms/step - loss: 12.6710 - acc: 0.2231\n",
      "Epoch 20/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 12.6353 - acc: 0.2229\n",
      "Epoch 21/150\n",
      "3890/3890 [==============================] - 6848s 2s/step - loss: 13.3573 - acc: 0.1781\n",
      "Epoch 22/150\n",
      "3890/3890 [==============================] - 315s 81ms/step - loss: 13.3608 - acc: 0.1789\n",
      "Epoch 23/150\n",
      "3890/3890 [==============================] - 301s 77ms/step - loss: 13.3871 - acc: 0.1763\n",
      "Epoch 24/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 7.5945 - acc: 0.2321\n",
      "Epoch 25/150\n",
      "3890/3890 [==============================] - 299s 77ms/step - loss: 1.9384 - acc: 0.3620\n",
      "Epoch 26/150\n",
      "3890/3890 [==============================] - 306s 79ms/step - loss: 1.8162 - acc: 0.4039\n",
      "Epoch 27/150\n",
      "3890/3890 [==============================] - 300s 77ms/step - loss: 1.8701 - acc: 0.4118\n",
      "Epoch 28/150\n",
      "3890/3890 [==============================] - 300s 77ms/step - loss: 1.7135 - acc: 0.4604\n",
      "Epoch 29/150\n",
      "3890/3890 [==============================] - 306s 79ms/step - loss: 1.8521 - acc: 0.4761\n",
      "Epoch 30/150\n",
      "3890/3890 [==============================] - 319s 82ms/step - loss: 1.6431 - acc: 0.5555\n",
      "Epoch 31/150\n",
      "3890/3890 [==============================] - 308s 79ms/step - loss: 1.6320 - acc: 0.5735\n",
      "Epoch 32/150\n",
      "3890/3890 [==============================] - 312s 80ms/step - loss: 1.8686 - acc: 0.6039\n",
      "Epoch 33/150\n",
      "3890/3890 [==============================] - 333s 86ms/step - loss: 1.5297 - acc: 0.6496\n",
      "Epoch 34/150\n",
      "3890/3890 [==============================] - 317s 82ms/step - loss: 1.5701 - acc: 0.6740\n",
      "Epoch 35/150\n",
      "3890/3890 [==============================] - 297s 76ms/step - loss: 1.6389 - acc: 0.6905\n",
      "Epoch 36/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 1.7050 - acc: 0.7180\n",
      "Epoch 37/150\n",
      "3890/3890 [==============================] - 296s 76ms/step - loss: 1.5797 - acc: 0.7329\n",
      "Epoch 38/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.4339 - acc: 0.7440\n",
      "Epoch 39/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 1.4943 - acc: 0.7674\n",
      "Epoch 40/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.5858 - acc: 0.7648\n",
      "Epoch 41/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 1.5060 - acc: 0.7668\n",
      "Epoch 42/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.3319 - acc: 0.7851\n",
      "Epoch 43/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.3256 - acc: 0.7828\n",
      "Epoch 44/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 1.3264 - acc: 0.7933\n",
      "Epoch 45/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 1.2925 - acc: 0.7907\n",
      "Epoch 46/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.1977 - acc: 0.7977\n",
      "Epoch 47/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.2422 - acc: 0.8046\n",
      "Epoch 48/150\n",
      "3890/3890 [==============================] - 296s 76ms/step - loss: 1.2612 - acc: 0.8033\n",
      "Epoch 49/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 1.2690 - acc: 0.8026\n",
      "Epoch 50/150\n",
      "3890/3890 [==============================] - 295s 76ms/step - loss: 1.2506 - acc: 0.7964\n",
      "Epoch 51/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.1107 - acc: 0.8177\n",
      "Epoch 52/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.2283 - acc: 0.8069\n",
      "Epoch 53/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.0657 - acc: 0.8288\n",
      "Epoch 54/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 1.0955 - acc: 0.8260\n",
      "Epoch 55/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 1.1372 - acc: 0.8234\n",
      "Epoch 56/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.0985 - acc: 0.8262\n",
      "Epoch 57/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.0360 - acc: 0.8386\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3890/3890 [==============================] - 294s 76ms/step - loss: 1.0541 - acc: 0.8237\n",
      "Epoch 59/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 1.0587 - acc: 0.8460\n",
      "Epoch 60/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 1.0587 - acc: 0.8308\n",
      "Epoch 61/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 0.9956 - acc: 0.8409\n",
      "Epoch 62/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 0.9683 - acc: 0.8419\n",
      "Epoch 63/150\n",
      "3890/3890 [==============================] - 292s 75ms/step - loss: 1.0642 - acc: 0.8262\n",
      "Epoch 64/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.0043 - acc: 0.8393\n",
      "Epoch 65/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.0261 - acc: 0.8368\n",
      "Epoch 66/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.0470 - acc: 0.8368\n",
      "Epoch 67/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 0.9666 - acc: 0.8568\n",
      "Epoch 68/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 0.9818 - acc: 0.8447\n",
      "Epoch 69/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.0036 - acc: 0.8494\n",
      "Epoch 70/150\n",
      "3890/3890 [==============================] - 668s 172ms/step - loss: 1.0011 - acc: 0.8386\n",
      "Epoch 71/150\n",
      "3890/3890 [==============================] - 310s 80ms/step - loss: 0.9652 - acc: 0.8476\n",
      "Epoch 72/150\n",
      "3890/3890 [==============================] - 296s 76ms/step - loss: 1.0004 - acc: 0.8458\n",
      "Epoch 73/150\n",
      "3890/3890 [==============================] - 295s 76ms/step - loss: 0.9113 - acc: 0.8571\n",
      "Epoch 74/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 0.9190 - acc: 0.8481\n",
      "Epoch 75/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 0.9293 - acc: 0.8578\n",
      "Epoch 76/150\n",
      "3890/3890 [==============================] - 294s 75ms/step - loss: 0.9227 - acc: 0.8442\n",
      "Epoch 77/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 0.9207 - acc: 0.8563\n",
      "Epoch 78/150\n",
      "3890/3890 [==============================] - 294s 75ms/step - loss: 1.0008 - acc: 0.8455\n",
      "Epoch 79/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 0.9516 - acc: 0.8532\n",
      "Epoch 80/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 0.9054 - acc: 0.8548\n",
      "Epoch 81/150\n",
      "3890/3890 [==============================] - 294s 75ms/step - loss: 0.9947 - acc: 0.8424\n",
      "Epoch 82/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 0.9223 - acc: 0.8558\n",
      "Epoch 83/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 0.9151 - acc: 0.8488\n",
      "Epoch 84/150\n",
      "3890/3890 [==============================] - 4074s 1s/step - loss: 0.9313 - acc: 0.8468\n",
      "Epoch 85/150\n",
      "3890/3890 [==============================] - 311s 80ms/step - loss: 0.8834 - acc: 0.8558\n",
      "Epoch 86/150\n",
      "3890/3890 [==============================] - 297s 76ms/step - loss: 0.8907 - acc: 0.8568\n",
      "Epoch 87/150\n",
      "3890/3890 [==============================] - 305s 78ms/step - loss: 0.9267 - acc: 0.8447\n",
      "Epoch 88/150\n",
      "3890/3890 [==============================] - 300s 77ms/step - loss: 0.9182 - acc: 0.8542\n",
      "Epoch 89/150\n",
      "3890/3890 [==============================] - 315s 81ms/step - loss: 0.9526 - acc: 0.8473\n",
      "Epoch 90/150\n",
      "3890/3890 [==============================] - 313s 81ms/step - loss: 0.9677 - acc: 0.8535\n",
      "Epoch 91/150\n",
      "3890/3890 [==============================] - 304s 78ms/step - loss: 0.9058 - acc: 0.8532\n",
      "Epoch 92/150\n",
      "3890/3890 [==============================] - 301s 77ms/step - loss: 0.9651 - acc: 0.8558\n",
      "Epoch 93/150\n",
      "3890/3890 [==============================] - 306s 79ms/step - loss: 0.9301 - acc: 0.8545\n",
      "Epoch 94/150\n",
      "3890/3890 [==============================] - 308s 79ms/step - loss: 0.9155 - acc: 0.8504\n",
      "Epoch 95/150\n",
      "3890/3890 [==============================] - 308s 79ms/step - loss: 0.9271 - acc: 0.8501\n",
      "Epoch 96/150\n",
      "3890/3890 [==============================] - 326s 84ms/step - loss: 0.8799 - acc: 0.8594\n",
      "Epoch 97/150\n",
      "3890/3890 [==============================] - 314s 81ms/step - loss: 0.9963 - acc: 0.8350\n",
      "Epoch 98/150\n",
      "3890/3890 [==============================] - 309s 79ms/step - loss: 0.9556 - acc: 0.8496\n",
      "Epoch 99/150\n",
      "3890/3890 [==============================] - 307s 79ms/step - loss: 0.9454 - acc: 0.8519\n",
      "Epoch 100/150\n",
      "3890/3890 [==============================] - 300s 77ms/step - loss: 0.9434 - acc: 0.8442\n",
      "Epoch 101/150\n",
      "3890/3890 [==============================] - 301s 77ms/step - loss: 0.9730 - acc: 0.8414\n",
      "Epoch 102/150\n",
      "3890/3890 [==============================] - 302s 78ms/step - loss: 0.8744 - acc: 0.8591\n",
      "Epoch 103/150\n",
      "3890/3890 [==============================] - 300s 77ms/step - loss: 0.9010 - acc: 0.8661\n",
      "Epoch 104/150\n",
      "3890/3890 [==============================] - 302s 78ms/step - loss: 0.9182 - acc: 0.8550\n",
      "Epoch 105/150\n",
      "3890/3890 [==============================] - 305s 78ms/step - loss: 0.9212 - acc: 0.8614\n",
      "Epoch 106/150\n",
      "3890/3890 [==============================] - 311s 80ms/step - loss: 0.9894 - acc: 0.8537\n",
      "Epoch 107/150\n",
      "3890/3890 [==============================] - 316s 81ms/step - loss: 0.9160 - acc: 0.8553\n",
      "Epoch 108/150\n",
      "3890/3890 [==============================] - 323s 83ms/step - loss: 0.8892 - acc: 0.8540\n",
      "Epoch 109/150\n",
      "3890/3890 [==============================] - 322s 83ms/step - loss: 0.9111 - acc: 0.8486\n",
      "Epoch 110/150\n",
      "3890/3890 [==============================] - 318s 82ms/step - loss: 0.9317 - acc: 0.8519\n",
      "Epoch 111/150\n",
      "3890/3890 [==============================] - 321s 82ms/step - loss: 0.8629 - acc: 0.8653\n",
      "Epoch 112/150\n",
      "3890/3890 [==============================] - 318s 82ms/step - loss: 0.8968 - acc: 0.8519\n",
      "Epoch 113/150\n",
      "3890/3890 [==============================] - 316s 81ms/step - loss: 0.9226 - acc: 0.8468\n",
      "Epoch 114/150\n",
      "3890/3890 [==============================] - 317s 81ms/step - loss: 0.8581 - acc: 0.8653\n",
      "Epoch 115/150\n",
      "3890/3890 [==============================] - 320s 82ms/step - loss: 0.8758 - acc: 0.8573\n",
      "Epoch 116/150\n",
      "3890/3890 [==============================] - 318s 82ms/step - loss: 1.2548 - acc: 0.8254\n",
      "Epoch 117/150\n",
      "3890/3890 [==============================] - 320s 82ms/step - loss: 0.9573 - acc: 0.8491\n",
      "Epoch 118/150\n",
      "3890/3890 [==============================] - 319s 82ms/step - loss: 0.9144 - acc: 0.8614\n",
      "Epoch 119/150\n",
      "3890/3890 [==============================] - 323s 83ms/step - loss: 0.8988 - acc: 0.8501\n",
      "Epoch 120/150\n",
      "3890/3890 [==============================] - 321s 82ms/step - loss: 0.9265 - acc: 0.8506\n",
      "Epoch 121/150\n",
      "3890/3890 [==============================] - 324s 83ms/step - loss: 0.8926 - acc: 0.8620\n",
      "Epoch 122/150\n",
      "3890/3890 [==============================] - 322s 83ms/step - loss: 0.8860 - acc: 0.8594\n",
      "Epoch 123/150\n",
      "3890/3890 [==============================] - 324s 83ms/step - loss: 0.8957 - acc: 0.8614\n",
      "Epoch 124/150\n",
      "3890/3890 [==============================] - 324s 83ms/step - loss: 0.8640 - acc: 0.8689\n",
      "Epoch 125/150\n",
      "3890/3890 [==============================] - 326s 84ms/step - loss: 0.9057 - acc: 0.8558\n",
      "Epoch 126/150\n",
      "3890/3890 [==============================] - 297s 76ms/step - loss: 0.8577 - acc: 0.8612\n",
      "Epoch 127/150\n",
      "3890/3890 [==============================] - 295s 76ms/step - loss: 0.9516 - acc: 0.8491\n",
      "Epoch 128/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 0.8376 - acc: 0.8676\n",
      "Epoch 129/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 0.8835 - acc: 0.8612\n",
      "Epoch 130/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 0.8659 - acc: 0.8645\n",
      "Epoch 131/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 0.8645 - acc: 0.8542\n",
      "Epoch 132/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 1.0047 - acc: 0.8483\n",
      "Epoch 133/150\n",
      "3890/3890 [==============================] - 293s 75ms/step - loss: 0.9119 - acc: 0.8620\n",
      "Epoch 134/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 0.8926 - acc: 0.8535\n",
      "Epoch 135/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 0.8490 - acc: 0.8702\n",
      "Epoch 136/150\n",
      "3890/3890 [==============================] - 294s 76ms/step - loss: 0.8783 - acc: 0.8638\n",
      "Epoch 137/150\n",
      "3890/3890 [==============================] - 294s 75ms/step - loss: 0.8820 - acc: 0.8607\n",
      "Epoch 138/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3890/3890 [==============================] - 12594s 3s/step - loss: 0.8937 - acc: 0.8537\n",
      "Epoch 139/150\n",
      "3890/3890 [==============================] - 325s 83ms/step - loss: 0.8553 - acc: 0.8769\n",
      "Epoch 140/150\n",
      "3890/3890 [==============================] - 328s 84ms/step - loss: 0.9169 - acc: 0.8501\n",
      "Epoch 141/150\n",
      "3890/3890 [==============================] - 334s 86ms/step - loss: 0.8711 - acc: 0.8550\n",
      "Epoch 142/150\n",
      "3890/3890 [==============================] - 341s 88ms/step - loss: 0.8828 - acc: 0.8643\n",
      "Epoch 143/150\n",
      "3890/3890 [==============================] - 344s 89ms/step - loss: 0.8702 - acc: 0.8648\n",
      "Epoch 144/150\n",
      "3890/3890 [==============================] - 341s 88ms/step - loss: 0.8712 - acc: 0.8630\n",
      "Epoch 145/150\n",
      "3890/3890 [==============================] - 341s 88ms/step - loss: 0.8869 - acc: 0.8568\n",
      "Epoch 146/150\n",
      "3890/3890 [==============================] - 340s 87ms/step - loss: 0.8741 - acc: 0.8591\n",
      "Epoch 147/150\n",
      "3890/3890 [==============================] - 326s 84ms/step - loss: 0.8527 - acc: 0.8656\n",
      "Epoch 148/150\n",
      "3890/3890 [==============================] - 344s 89ms/step - loss: 0.8756 - acc: 0.8635\n",
      "Epoch 149/150\n",
      "3890/3890 [==============================] - 412s 106ms/step - loss: 0.9337 - acc: 0.8481\n",
      "Epoch 150/150\n",
      "3890/3890 [==============================] - 361s 93ms/step - loss: 1.0683 - acc: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d97ffb6a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433/433 [==============================] - 11s 26ms/step\n",
      "loss, accuracy =  [10.414051181449626, 0.27482679032012991]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from matplotlib.pyplot import subplots, show, figure, plot, xlabel, ylabel, legend, twinx, gca\n",
    "from numpy import array, append, mean, argmin, ones, concatenate, uint8\n",
    "from numpy.random import random_integers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import imread\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.misc import imresize\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import cv2\n",
    " \n",
    "#Initial\n",
    "print('----------介面初始化----------')\n",
    "sns.set_style('white')\n",
    "flowersCategory=['daisy','dandelion','rose','sunflower','tulip']\n",
    "\n",
    "#One-Hot Encoding\n",
    "mapping = {'daisy': 0,\n",
    "         'dandelion': 1,\n",
    "         'rose': 2,\n",
    "         'sunflower': 3,\n",
    "         'tulip': 4\n",
    "        }\n",
    "\n",
    "#read pic\n",
    "print('----------讀取並合併圖片----------')\n",
    "image_list = []\n",
    "one_hot_labels = []\n",
    "#sort by labels.xls\n",
    "\n",
    "for path2 in flowersCategory:\n",
    "\tfor filename in glob.glob('flowers/' + path2 + '/*.jpg'):\n",
    "\t\tim=imread(filename)\n",
    "\t\tim = cv2.resize(im,(255,340),interpolation=cv2.INTER_LINEAR)\n",
    "\t\timage_list.append(array(im))\n",
    "\t\tone_hot = array([0,0,0,0,0])\n",
    "\t\tone_hot[mapping[path2]] = 1.\n",
    "\t\tone_hot_labels.append(one_hot)\n",
    "\n",
    "#用Keras創建CNN\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.3, input_shape=((340,255 , 3))))\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(340,255 , 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())  #3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64, kernel_regularizer= 'l2'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, kernel_regularizer= 'l2'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'],)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "image_list = array(image_list)\n",
    "one_hot_labels = array(one_hot_labels, dtype=uint8)\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_list, one_hot_labels, test_size = .1)\n",
    "\n",
    "#start training\n",
    "hist = model.fit(X_train, y_train, epochs = 150, batch_size = 64, verbose = 1)\n",
    "\n",
    "figure()\n",
    "xlabel('epochs')\n",
    "plot(hist.history['loss'])\n",
    "ylabel('loss')\n",
    "legend(['loss'])\n",
    "twinx(gca())\n",
    "plot(hist.history['acc'], 'r')\n",
    "ylabel('accuracy')\n",
    "legend(['acc'])\n",
    "show()\n",
    "\n",
    "print('loss, accuracy = ', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
